{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"Data/all_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good luck to all Fury-Haney players playing th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user @user awe!!! #cnn so bias and does...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user don't leave me</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Odd watching #Antifa extremists going full spe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Really.....#Jumanji 2....w/ The Rock, Jack Bla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  Good luck to all Fury-Haney players playing th...      0\n",
       "1  @user @user @user awe!!! #cnn so bias and does...      0\n",
       "2                             @user don't leave me        3\n",
       "3  Odd watching #Antifa extremists going full spe...      0\n",
       "4  Really.....#Jumanji 2....w/ The Rock, Jack Bla...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_relu(nn.Module):\n",
    "    def __init__(self, input_dim=10, num_hidden=1, hidden_dim=100, output_dim=4, dropout=0.5):\n",
    "        \"\"\"\n",
    "        input_dim: Number of cells in the input layer\n",
    "        num_hidden: Number of hidden layers\n",
    "        hidden_dim: Number of cells in each hidden_layer\n",
    "        output_dim: Number of cells in the output dimension \n",
    "        dropout: \n",
    "        \"\"\"\n",
    "        # Building the network from here\n",
    "        super(MLP_relu, self).__init__()\n",
    "        \n",
    "        # Class attributes\n",
    "        self.input_dim = input_dim\n",
    "        self.num_hidden = num_hidden\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Hidden layers\n",
    "        hidden = [nn.Linear(input_dim, hidden_dim) if i==0 else nn.Linear(hidden_dim, hidden_dim) for i in range(num_hidden)]\n",
    "        self.linears = nn.ModuleList(hidden)\n",
    "        \n",
    "        # Output layer\n",
    "        self.ol = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, data, **kwargs):\n",
    "        # To float\n",
    "        X = data.float()\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i, hl in enumerate(self.linears):\n",
    "            X = self.linears[i](X)\n",
    "            X = F.relu(X)\n",
    "            X = self.dropout(X)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.ol(X)\n",
    "        out = F.softmax(out, dim = -1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe1b1dd6f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "torch.manual_seed(1492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To automatically detect input size\n",
    "# https://github.com/skorch-dev/skorch/issues/584\n",
    "class MyNet(NeuralNetClassifier):\n",
    "    def check_data(self, X, y):\n",
    "        super().check_data(X, y)\n",
    "        if self.module_.input_dim != X.shape[1]:\n",
    "            self.set_params(module__input_dim=X.shape[1])\n",
    "            self.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from IPython.display import clear_output\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "Given the number of parameters we are going to try and the size of the data, sklearn's grid-search is slower than a manual grid-search where we save the parameters to da csv file. We will perform 4 different grid-searches, one for each method to handle the imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_mlp(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    # Variables for the status\n",
    "    tot = len(hidden_layers)*len(hidden_size)*len(learning_rate)*len(stopwords)*len(ngrams)\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # List to save the output\n",
    "    hidl = []\n",
    "    hids = []\n",
    "    lrs = []\n",
    "    stwds = []\n",
    "    ngs = []\n",
    "    err = []\n",
    "    ttime = []\n",
    "    \n",
    "    for st in stopwords:\n",
    "        for ng in ngrams:\n",
    "            for hl in hidden_layers: \n",
    "                for hs in hidden_size: \n",
    "                    for lr in learning_rate:\n",
    "                        # Vectorizer\n",
    "                        TFIDF = TfidfVectorizer(stop_words = st,  ngram_range=(1, ng))\n",
    "                        \n",
    "                        # Scaler\n",
    "                        ss = StandardScaler(with_mean=False)\n",
    "                        \n",
    "                        # MLP\n",
    "                        MLP_net = MyNet(\n",
    "                                MLP_relu(num_hidden=hl, hidden_dim=hs, output_dim = 4, dropout=0.2),\n",
    "                                max_epochs=50,\n",
    "                                callbacks=[EarlyStopping()],\n",
    "                                lr=lr,\n",
    "                                batch_size = 64,\n",
    "                                device='cpu',\n",
    "                                verbose=0\n",
    "                                )\n",
    "                        \n",
    "                        # Pipeline\n",
    "                        pipe = Pipeline([('tfidf', TFIDF), ('ss', ss), ('mlp', MLP_net)])\n",
    "                        \n",
    "                        # Cross validation\n",
    "                        scores = cross_validate(pipe, X_train.values.ravel(), y_train.values.ravel(), scoring='f1_weighted', cv=folds)\n",
    "                        \n",
    "                        # Saving variables\n",
    "                        hidl.append(hl)\n",
    "                        hids.append(hs)\n",
    "                        lrs.append(lr)\n",
    "                        if st is not None:\n",
    "                            stwds.append(st)\n",
    "                        else:\n",
    "                            stwds.append(\"None\")\n",
    "                        ngs.append(ng)\n",
    "                        err.append(np.mean(scores['test_score']))\n",
    "                        ttime.append(np.mean(scores['fit_time']))\n",
    "                            \n",
    "                        # Print status\n",
    "                        i = i + 1\n",
    "                        t = time.time()-t0\n",
    "                        clear_output(wait=True)\n",
    "                        total = (tot/i)*(t/(60*60))\n",
    "                        print(i/tot*100,\"% done\")\n",
    "                        print(\"Estimated remaining time:\", round(total-t/(60*60),3), \"hours\")\n",
    "                        print(t/(60*60),\"elapsed hours\")\n",
    "\n",
    "    return pd.DataFrame([hidl, hids, lrs, stwds, ngs, err, ttime], \n",
    "                index = [\"hidden_layers\", \"hidden_size\", \"learning_rate\", \"stopwords\", \"ngrams\", \"err\", \"time\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_mlp_RUS(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3):\n",
    "    from imblearn.pipeline import Pipeline \n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    # Variables for the status\n",
    "    tot = len(hidden_layers)*len(hidden_size)*len(learning_rate)*len(stopwords)*len(ngrams)\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # List to save the output\n",
    "    hidl = []\n",
    "    hids = []\n",
    "    lrs = []\n",
    "    stwds = []\n",
    "    ngs = []\n",
    "    err = []\n",
    "    ttime = []\n",
    "    \n",
    "    for st in stopwords:\n",
    "        for ng in ngrams:\n",
    "            for hl in hidden_layers: \n",
    "                for hs in hidden_size: \n",
    "                    for lr in learning_rate:\n",
    "                        # Vectorizer\n",
    "                        TFIDF = TfidfVectorizer(stop_words = st,  ngram_range=(1, ng))\n",
    "                        \n",
    "                        # Scaler\n",
    "                        ss = StandardScaler(with_mean=False)\n",
    "                        \n",
    "                        # Undersampling\n",
    "                        us = RandomUnderSampler(random_state=1492)\n",
    "                        \n",
    "                        # MLP\n",
    "                        MLP_net = MyNet(\n",
    "                                MLP_relu(num_hidden=hl, hidden_dim=hs, output_dim = 4, dropout=0.2),\n",
    "                                max_epochs=50,\n",
    "                                callbacks=[EarlyStopping()],\n",
    "                                lr=lr,\n",
    "                                batch_size = 64,\n",
    "                                device='cpu',\n",
    "                                verbose=0\n",
    "                                )\n",
    "                        \n",
    "                        # Pipeline\n",
    "                        pipe = Pipeline([('tfidf', TFIDF), ('ss', ss), ('us', us), ('mlp', MLP_net)])\n",
    "                        \n",
    "                        # Cross validation\n",
    "                        scores = cross_validate(pipe, X_train.values.ravel(), y_train.values.ravel(), scoring='f1_weighted', cv=folds)\n",
    "                        \n",
    "                        # Saving variables\n",
    "                        hidl.append(hl)\n",
    "                        hids.append(hs)\n",
    "                        lrs.append(lr)\n",
    "                        if st is not None:\n",
    "                            stwds.append(st)\n",
    "                        else:\n",
    "                            stwds.append(\"None\")\n",
    "                        ngs.append(ng)\n",
    "                        err.append(np.mean(scores['test_score']))\n",
    "                        ttime.append(np.mean(scores['fit_time']))\n",
    "                            \n",
    "                        # Print status\n",
    "                        i = i + 1\n",
    "                        t = time.time()-t0\n",
    "                        clear_output(wait=True)\n",
    "                        total = (tot/i)*(t/(60*60))\n",
    "                        print(i/tot*100,\"% done\")\n",
    "                        print(\"Estimated remaining time:\", round(total-t/(60*60),3), \"hours\")\n",
    "                        print(t/(60*60),\"elapsed hours\")\n",
    "\n",
    "    return pd.DataFrame([hidl, hids, lrs, stwds, ngs, err, ttime], \n",
    "                index = [\"hidden_layers\", \"hidden_size\", \"learning_rate\", \"stopwords\", \"ngrams\", \"err\", \"time\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_mlp_ROS(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3):\n",
    "    from imblearn.pipeline import Pipeline \n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "    # Variables for the status\n",
    "    tot = len(hidden_layers)*len(hidden_size)*len(learning_rate)*len(stopwords)*len(ngrams)\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # List to save the output\n",
    "    hidl = []\n",
    "    hids = []\n",
    "    lrs = []\n",
    "    stwds = []\n",
    "    ngs = []\n",
    "    err = []\n",
    "    ttime = []\n",
    "    \n",
    "    for st in stopwords:\n",
    "        for ng in ngrams:\n",
    "            for hl in hidden_layers: \n",
    "                for hs in hidden_size: \n",
    "                    for lr in learning_rate:\n",
    "                        # Vectorizer\n",
    "                        TFIDF = TfidfVectorizer(stop_words = st,  ngram_range=(1, ng))\n",
    "                        \n",
    "                        # Scaler\n",
    "                        ss = StandardScaler(with_mean=False)\n",
    "                        \n",
    "                        # Oversampling\n",
    "                        os = RandomOverSampler(random_state=1492)\n",
    "                        \n",
    "                        # MLP\n",
    "                        MLP_net = MyNet(\n",
    "                                MLP_relu(num_hidden=hl, hidden_dim=hs, output_dim = 4, dropout=0.2),\n",
    "                                max_epochs=50,\n",
    "                                callbacks=[EarlyStopping()],\n",
    "                                lr=lr,\n",
    "                                batch_size = 64,\n",
    "                                device='cpu',\n",
    "                                verbose=0\n",
    "                                )\n",
    "                        \n",
    "                        # Pipeline\n",
    "                        pipe = Pipeline([('tfidf', TFIDF), ('ss', ss), ('os', os), ('mlp', MLP_net)])\n",
    "                        \n",
    "                        # Cross validation\n",
    "                        scores = cross_validate(pipe, X_train.values.ravel(), y_train.values.ravel(), scoring='f1_weighted', cv=folds)\n",
    "                        \n",
    "                        # Saving variables\n",
    "                        hidl.append(hl)\n",
    "                        hids.append(hs)\n",
    "                        lrs.append(lr)\n",
    "                        if st is not None:\n",
    "                            stwds.append(st)\n",
    "                        else:\n",
    "                            stwds.append(\"None\")\n",
    "                        ngs.append(ng)\n",
    "                        err.append(np.mean(scores['test_score']))\n",
    "                        ttime.append(np.mean(scores['fit_time']))\n",
    "                            \n",
    "                        # Print status\n",
    "                        i = i + 1\n",
    "                        t = time.time()-t0\n",
    "                        clear_output(wait=True)\n",
    "                        total = (tot/i)*(t/(60*60))\n",
    "                        print(i/tot*100,\"% done\")\n",
    "                        print(\"Estimated remaining time:\", round(total-t/(60*60),3), \"hours\")\n",
    "                        print(t/(60*60),\"elapsed hours\")\n",
    "\n",
    "    return pd.DataFrame([hidl, hids, lrs, stwds, ngs, err, ttime], \n",
    "                index = [\"hidden_layers\", \"hidden_size\", \"learning_rate\", \"stopwords\", \"ngrams\", \"err\", \"time\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_mlp_SMOTE(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3):\n",
    "    from imblearn.pipeline import Pipeline \n",
    "    from imblearn.over_sampling import SMOTE \n",
    "    # Variables for the status\n",
    "    tot = len(hidden_layers)*len(hidden_size)*len(learning_rate)*len(stopwords)*len(ngrams)\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # List to save the output\n",
    "    hidl = []\n",
    "    hids = []\n",
    "    lrs = []\n",
    "    stwds = []\n",
    "    ngs = []\n",
    "    err = []\n",
    "    ttime = []\n",
    "    \n",
    "    for st in stopwords:\n",
    "        for ng in ngrams:\n",
    "            for hl in hidden_layers: \n",
    "                for hs in hidden_size: \n",
    "                    for lr in learning_rate:\n",
    "                        # Vectorizer\n",
    "                        TFIDF = TfidfVectorizer(stop_words = st,  ngram_range=(1, ng))\n",
    "                        \n",
    "                        # Scaler\n",
    "                        ss = StandardScaler(with_mean=False)\n",
    "                        \n",
    "                        # SMOTE\n",
    "                        sm = SMOTE(random_state=1492)\n",
    "                        \n",
    "                        # MLP\n",
    "                        MLP_net = MyNet(\n",
    "                                MLP_relu(num_hidden=hl, hidden_dim=hs, output_dim = 4, dropout=0.2),\n",
    "                                max_epochs=50,\n",
    "                                callbacks=[EarlyStopping()],\n",
    "                                lr=lr,\n",
    "                                batch_size = 64,\n",
    "                                device='cpu',\n",
    "                                verbose=0\n",
    "                                )\n",
    "                        \n",
    "                        # Pipeline\n",
    "                        pipe = Pipeline([('tfidf', TFIDF), ('ss', ss), ('sm', sm), ('mlp', MLP_net)])\n",
    "                        \n",
    "                        # Cross validation\n",
    "                        scores = cross_validate(pipe, X_train.values.ravel(), y_train.values.ravel(), scoring='f1_weighted', cv=folds)\n",
    "                        \n",
    "                        # Saving variables\n",
    "                        hidl.append(hl)\n",
    "                        hids.append(hs)\n",
    "                        lrs.append(lr)\n",
    "                        if st is not None:\n",
    "                            stwds.append(st)\n",
    "                        else:\n",
    "                            stwds.append(\"None\")\n",
    "                        ngs.append(ng)\n",
    "                        err.append(np.mean(scores['test_score']))\n",
    "                        ttime.append(np.mean(scores['fit_time']))\n",
    "                            \n",
    "                        # Print status\n",
    "                        i = i + 1\n",
    "                        t = time.time()-t0\n",
    "                        clear_output(wait=True)\n",
    "                        total = (tot/i)*(t/(60*60))\n",
    "                        print(i/tot*100,\"% done\")\n",
    "                        print(\"Estimated remaining time:\", round(total-t/(60*60),3), \"hours\")\n",
    "                        print(t/(60*60),\"elapsed hours\")\n",
    "\n",
    "    return pd.DataFrame([hidl, hids, lrs, stwds, ngs, err, ttime], \n",
    "                index = [\"hidden_layers\", \"hidden_size\", \"learning_rate\", \"stopwords\", \"ngrams\", \"err\", \"time\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"Data/X_train.csv\")\n",
    "y_train = pd.read_csv(\"Data/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % done\n",
      "Estimated remaining time: 0.0 hours\n",
      "5.410855841173066 elapsed hours\n"
     ]
    }
   ],
   "source": [
    "stopwords = [None, \"english\"]\n",
    "ngrams = [1, 2]\n",
    "hidden_layers = [1, 10, 100, 1000]\n",
    "hidden_size = [1, 10, 100, 1000]\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "results_og = grid_search_mlp(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_og.to_csv(\"Grid-Search/MLP_OG.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>err</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592085</td>\n",
       "      <td>7.183023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.591318</td>\n",
       "      <td>7.929810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.591157</td>\n",
       "      <td>27.119740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590522</td>\n",
       "      <td>8.160554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590521</td>\n",
       "      <td>8.184138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.392635</td>\n",
       "      <td>10.439503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.388884</td>\n",
       "      <td>10.488548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384993</td>\n",
       "      <td>10.658334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.379850</td>\n",
       "      <td>10.475542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.376957</td>\n",
       "      <td>10.471427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_layers hidden_size learning_rate stopwords ngrams       err  \\\n",
       "11              1         100          0.05      None      1  0.592085   \n",
       "21             10           1          0.05      None      1  0.591318   \n",
       "190            10         100          0.01   english      1  0.591157   \n",
       "211           100         100          0.05   english      1  0.590522   \n",
       "196            10        1000          0.05   english      1  0.590521   \n",
       "..            ...         ...           ...       ...    ...       ...   \n",
       "109            10          10             1      None      2  0.392635   \n",
       "144          1000           1             1      None      2  0.388884   \n",
       "139           100        1000             1      None      2  0.384993   \n",
       "149          1000          10             1      None      2  0.379850   \n",
       "129           100          10             1      None      2  0.376957   \n",
       "\n",
       "          time  \n",
       "11    7.183023  \n",
       "21    7.929810  \n",
       "190  27.119740  \n",
       "211   8.160554  \n",
       "196   8.184138  \n",
       "..         ...  \n",
       "109  10.439503  \n",
       "144  10.488548  \n",
       "139  10.658334  \n",
       "149  10.475542  \n",
       "129  10.471427  \n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_og.sort_values(\"err\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % done\n",
      "Estimated remaining time: 0.0 hours\n",
      "2.526733169224527 elapsed hours\n"
     ]
    }
   ],
   "source": [
    "stopwords = [None, \"english\"]\n",
    "ngrams = [1, 2]\n",
    "hidden_layers = [1, 10, 100, 1000]\n",
    "hidden_size = [1, 10, 100, 1000]\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "results_us = grid_search_mlp_RUS(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_us.to_csv(\"Grid-Search/MLP_US.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>err</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462061</td>\n",
       "      <td>3.420971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459824</td>\n",
       "      <td>5.049016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458377</td>\n",
       "      <td>3.811890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457759</td>\n",
       "      <td>5.919978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457756</td>\n",
       "      <td>5.559218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.321363</td>\n",
       "      <td>3.959341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.321039</td>\n",
       "      <td>4.359269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.315730</td>\n",
       "      <td>3.975524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307146</td>\n",
       "      <td>4.167748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.295690</td>\n",
       "      <td>4.002366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_layers hidden_size learning_rate stopwords ngrams       err  \\\n",
       "197            10        1000          0.10   english      1  0.462061   \n",
       "176             1        1000          0.05   english      1  0.459824   \n",
       "192            10         100          0.10   english      1  0.458377   \n",
       "61           1000           1          0.05      None      1  0.457759   \n",
       "51            100         100          0.05      None      1  0.457756   \n",
       "..            ...         ...           ...       ...    ...       ...   \n",
       "118            10        1000          0.50      None      2  0.321363   \n",
       "94              1         100             1      None      2  0.321039   \n",
       "149          1000          10             1      None      2  0.315730   \n",
       "89              1          10             1      None      2  0.307146   \n",
       "154          1000         100             1      None      2  0.295690   \n",
       "\n",
       "         time  \n",
       "197  3.420971  \n",
       "176  5.049016  \n",
       "192  3.811890  \n",
       "61   5.919978  \n",
       "51   5.559218  \n",
       "..        ...  \n",
       "118  3.959341  \n",
       "94   4.359269  \n",
       "149  3.975524  \n",
       "89   4.167748  \n",
       "154  4.002366  \n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_us.sort_values(\"err\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % done\n",
      "Estimated remaining time: 0.0 hours\n",
      "12.259407487776544 elapsed hours\n"
     ]
    }
   ],
   "source": [
    "stopwords = [None, \"english\"]\n",
    "ngrams = [1, 2]\n",
    "hidden_layers = [1, 10, 100, 1000]\n",
    "hidden_size = [1, 10, 100, 1000]\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "results_os = grid_search_mlp_ROS(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_os.to_csv(\"Grid-Search/MLP_OS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>err</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600493</td>\n",
       "      <td>51.495731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.599556</td>\n",
       "      <td>53.446120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598831</td>\n",
       "      <td>53.995280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597562</td>\n",
       "      <td>43.685045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596482</td>\n",
       "      <td>59.614981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.336649</td>\n",
       "      <td>43.236211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.330946</td>\n",
       "      <td>37.492469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.317430</td>\n",
       "      <td>49.395968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.313934</td>\n",
       "      <td>43.729687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.309411</td>\n",
       "      <td>63.910153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_layers hidden_size learning_rate stopwords ngrams       err  \\\n",
       "170             1         100          0.01   english      1  0.600493   \n",
       "195            10        1000          0.01   english      1  0.599556   \n",
       "230          1000         100          0.01   english      1  0.598831   \n",
       "0               1           1          0.01      None      1  0.597562   \n",
       "45            100          10          0.01      None      1  0.596482   \n",
       "..            ...         ...           ...       ...    ...       ...   \n",
       "154          1000         100             1      None      2  0.336649   \n",
       "129           100          10             1      None      2  0.330946   \n",
       "99              1        1000             1      None      2  0.317430   \n",
       "124           100           1             1      None      2  0.313934   \n",
       "159          1000        1000             1      None      2  0.309411   \n",
       "\n",
       "          time  \n",
       "170  51.495731  \n",
       "195  53.446120  \n",
       "230  53.995280  \n",
       "0    43.685045  \n",
       "45   59.614981  \n",
       "..         ...  \n",
       "154  43.236211  \n",
       "129  37.492469  \n",
       "99   49.395968  \n",
       "124  43.729687  \n",
       "159  63.910153  \n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_os.sort_values(\"err\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % done\n",
      "Estimated remaining time: 0.0 hours\n",
      "10.711227911975648 elapsed hours\n"
     ]
    }
   ],
   "source": [
    "stopwords = [None, \"english\"]\n",
    "ngrams = [1, 2]\n",
    "hidden_layers = [1, 10, 100, 1000]\n",
    "hidden_size = [1, 10, 100, 1000]\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "results_sm = grid_search_mlp_SMOTE(hidden_layers, hidden_size, learning_rate, stopwords, ngrams, X_train, y_train, folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sm.to_csv(\"Grid-Search/MLP_SM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>err</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601016</td>\n",
       "      <td>52.654019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600227</td>\n",
       "      <td>15.264734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600118</td>\n",
       "      <td>15.023063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600030</td>\n",
       "      <td>13.553564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.599616</td>\n",
       "      <td>23.903095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.412521</td>\n",
       "      <td>32.502520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.412465</td>\n",
       "      <td>23.848836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.412335</td>\n",
       "      <td>10.591240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.406074</td>\n",
       "      <td>21.278053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.403756</td>\n",
       "      <td>33.357325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_layers hidden_size learning_rate stopwords ngrams       err  \\\n",
       "205           100          10          0.01   english      1  0.601016   \n",
       "231          1000         100          0.05   english      1  0.600227   \n",
       "66           1000          10          0.05      None      1  0.600118   \n",
       "11              1         100          0.05      None      1  0.600030   \n",
       "36             10        1000          0.05      None      1  0.599616   \n",
       "..            ...         ...           ...       ...    ...       ...   \n",
       "154          1000         100             1      None      2  0.412521   \n",
       "89              1          10             1      None      2  0.412465   \n",
       "29             10          10             1      None      1  0.412335   \n",
       "109            10          10             1      None      2  0.406074   \n",
       "104            10           1             1      None      2  0.403756   \n",
       "\n",
       "          time  \n",
       "205  52.654019  \n",
       "231  15.264734  \n",
       "66   15.023063  \n",
       "11   13.553564  \n",
       "36   23.903095  \n",
       "..         ...  \n",
       "154  32.502520  \n",
       "89   23.848836  \n",
       "29   10.591240  \n",
       "109  21.278053  \n",
       "104  33.357325  \n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sm.sort_values(\"err\", ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
